{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade tensorflow"
      ],
      "metadata": {
        "id": "E639m7bFiy0S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow_text==2.15"
      ],
      "metadata": {
        "id": "oazivmhQzxKZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout, Lambda, Subtract, LSTM, Embedding, Bidirectional,Flatten,GlobalAveragePooling1D\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.initializers import Constant\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras import regularizers\n",
        "from keras.layers import Dense, LSTM, Dropout, GRU, Bidirectional\n",
        "from keras.optimizers import SGD"
      ],
      "metadata": {
        "id": "u9ZOZKEpydng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TjstKouBnjrX"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "import string"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_text as text"
      ],
      "metadata": {
        "id": "Vg2DvxqkzmkU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "id": "PWSvq2HCpadW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "963d57c0-0ec1-454b-b10c-9ae5f944be0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "id": "UljW2QSrplcs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "caf02a2a-8e36-49d8-a4a6-4eaee9f35360"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Use the counterfactual generated file name here\n",
        "data = pd.read_csv('SourceToTarget.csv')"
      ],
      "metadata": {
        "id": "h-5mTLtEnppb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the number of rows in the DataFrame object using the built-in len() function\n",
        "num_lines = len(data)\n",
        "\n",
        "# Print the number of lines in the CSV file\n",
        "print(\"Number of lines in the CSV file: \", num_lines)"
      ],
      "metadata": {
        "id": "EZZV6injpBAU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Use the file whose labels have to be predicted\n",
        "df = pd.read_csv('TargetReviewFile.csv')"
      ],
      "metadata": {
        "id": "8y5J6VIRu_md"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "id": "hy06cljn4Wvf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#If the column names are not 'Label' and 'Review'\n",
        "\n",
        "old_label_name = 'label'\n",
        "new_label_name = 'Label'\n",
        "# Change the column name\n",
        "data.rename(columns={old_label_name: new_label_name}, inplace=True)\n",
        "\n",
        "old_review_name = 'generated_text'\n",
        "new_review_name = 'Review'\n",
        "# Change the column name\n",
        "data.rename(columns={old_review_name: new_review_name}, inplace=True)"
      ],
      "metadata": {
        "id": "X2Cm_ydY92fX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Only necessary if values of Label are not 0 and 1\n",
        "test_data = pd.concat([df[df['Label'] == label].sample(100, random_state=42) for label in [-1, 1]]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "test_data['Label'] = test_data['Label'].replace(-1,0)\n",
        "data['Label'] = data['Label'].replace(-1,0)"
      ],
      "metadata": {
        "id": "lPi_j9uBvpfz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the number of rows in the DataFrame object using the built-in len() function\n",
        "num_lines = len(data)\n",
        "\n",
        "# Print the number of lines in the CSV file\n",
        "print(\"Number of lines in the CSV file: \", num_lines)"
      ],
      "metadata": {
        "id": "hpR55lKwpUj3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the number of rows in the DataFrame object using the built-in len() function\n",
        "num_lines = len(test_data)\n",
        "\n",
        "# Print the number of lines in the CSV file\n",
        "print(\"Number of lines in the CSV file: \", num_lines)"
      ],
      "metadata": {
        "id": "N1ulmNf-Jhlp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(text):\n",
        "    # Convert text to lowercase\n",
        "    text = str(text)\n",
        "    text = text.lower()\n",
        "\n",
        "    # Tokenize text into words\n",
        "    words = nltk.word_tokenize(text)\n",
        "\n",
        "    # Remove stopwords\n",
        "    stop_words = set(nltk.corpus.stopwords.words('english'))\n",
        "    words = [word for word in words if word not in stop_words]\n",
        "\n",
        "    # Remove punctuation\n",
        "    words = [word for word in words if word not in string.punctuation]\n",
        "\n",
        "    # Join the words back into a single string\n",
        "    processed_text = ' '.join(words)\n",
        "\n",
        "    return processed_text"
      ],
      "metadata": {
        "id": "hb4SJZFAoFNl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['Review'] = data['Review'].apply(preprocess_text)\n",
        "test_data['Review'] = test_data['Review'].apply(preprocess_text)"
      ],
      "metadata": {
        "id": "mwDMKUDrphwd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = data['Review']\n",
        "y_train = data['Label']"
      ],
      "metadata": {
        "id": "_vl2LjTCp3cp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_test = test_data['Review']\n",
        "y_test = test_data['Label']"
      ],
      "metadata": {
        "id": "oUFIViS-tSXx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Embedding and Training**"
      ],
      "metadata": {
        "id": "rgI7BK050bbW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow_hub"
      ],
      "metadata": {
        "id": "1PPgJbblrOrT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_hub as hub\n",
        "#initialize tensorflow hub layers\n",
        "bert_preprocess = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\")\n",
        "bert_encoder = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\")"
      ],
      "metadata": {
        "id": "9NeIXbqJrrpn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#function to build the model\n",
        "def build_model():\n",
        "  text_input = Input(shape=(), dtype=tf.string, name='text')\n",
        "  preprocessed_text = bert_preprocess(text_input)\n",
        "  outputs = bert_encoder(preprocessed_text)\n",
        "  l = tf.keras.layers.Reshape((1,768))(outputs['pooled_output'])\n",
        "  l = Bidirectional(LSTM(128,return_sequences = False))(l)\n",
        "  l = Dropout(0.2,name=\"dropout\")(l)\n",
        "  l = Dense(1, activation='sigmoid',name='output')(l)\n",
        "  model = Model(inputs=[text_input], outputs = [l])\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['Precision','accuracy','Recall'])\n",
        "  return model"
      ],
      "metadata": {
        "id": "VONqCT0V0CV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report\n",
        "#Define k-fold cross validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "fold_no = 1\n",
        "accuracies, precisions, recalls = [],[],[]\n",
        "\n",
        "# Loop through each fold\n",
        "for train_index, val_index in kf.split(x_train):\n",
        "    print(f\"\\nTraining on Fold {fold_no}...\")\n",
        "\n",
        "    # Split the data\n",
        "    x_train_fold, x_val_fold = x_train[train_index], x_train[val_index]\n",
        "    y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
        "\n",
        "    # Build and train the model\n",
        "    model = build_model()\n",
        "    history = model.fit(x_train_fold, y_train_fold,\n",
        "                        epochs=10,  # Use fewer epochs for demonstration\n",
        "                        verbose=2,\n",
        "                        validation_data=(x_val_fold, y_val_fold),\n",
        "                        batch_size=256)\n",
        "\n",
        "    # Evaluate on the validation set\n",
        "    y_val_pred = model.predict(x_val_fold)\n",
        "    y_val_pred_final = [0 if i < 0.6 else 1 for i in y_val_pred]\n",
        "\n",
        "    accuracy = accuracy_score(y_val_fold, y_val_pred_final)\n",
        "    precision = precision_score(y_val_fold, y_val_pred_final)\n",
        "    recall = recall_score(y_val_fold, y_val_pred_final)\n",
        "\n",
        "    print(f\"Fold {fold_no} Results - Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}\")\n",
        "\n",
        "    accuracies.append(accuracy)\n",
        "    precisions.append(precision)\n",
        "    recalls.append(recall)\n",
        "\n",
        "    fold_no += 1"
      ],
      "metadata": {
        "id": "BJs1K9zU7beD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate mean and mean deviation\n",
        "def mean_deviation(values):\n",
        "    mean_value = np.mean(values)\n",
        "    deviations = [abs(x - mean_value) for x in values]\n",
        "    return mean_value, np.mean(deviations)\n",
        "\n",
        "accuracy_mean, accuracy_dev = mean_deviation(accuracies)\n",
        "precision_mean, precision_dev = mean_deviation(precisions)\n",
        "recall_mean, recall_dev = mean_deviation(recalls)\n",
        "\n",
        "# Display average metrics and mean deviation\n",
        "print(\"\\nAverage Results across 5 folds:\")\n",
        "print(f\"Accuracy: {accuracy_mean:.4f} ± {accuracy_dev:.4f}\")\n",
        "print(f\"Precision: {precision_mean:.4f} ± {precision_dev:.4f}\")\n",
        "print(f\"Recall: {recall_mean:.4f} ± {recall_dev:.4f}\")"
      ],
      "metadata": {
        "id": "f7QNrgQDyhZk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}