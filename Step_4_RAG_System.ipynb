{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YnOAMAre6dfD"
      },
      "outputs": [],
      "source": [
        "pip install chromadb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HV-R8cDHl1Rn"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"GEMINI_API_KEY\"] = \"AIzaSyC--4S4iuAK_z8mTAgKsZiLHq5kMS1D_K4\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A-ng32yW7V3h"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a4G5w80O6ahI"
      },
      "outputs": [],
      "source": [
        "# replace the path with your target file path\n",
        "df = pd.read_csv('/content/targetfile.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bPQ1CIbaPbP-"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S8OmuIHS7eLn"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming df is your DataFrame with a column named 'text'\n",
        "# and each row contains a single review\n",
        "def split_text(text: str):\n",
        "    \"\"\"\n",
        "    Splits a text string into a list of non-empty substrings based on the specified pattern.\n",
        "    The \"\\n \\n\" pattern will split the document para by para\n",
        "    Parameters:\n",
        "    - text (str): The input text to be split.\n",
        "\n",
        "    Returns:\n",
        "    - List[str]: A list containing non-empty substrings obtained by splitting the input text.\n",
        "    \"\"\"\n",
        "    split_text = re.split('\\n \\n', text)\n",
        "    return [i for i in split_text if i != \"\"]\n",
        "\n",
        "# Assuming df is your DataFrame with a column named 'text'\n",
        "# and each row contains a single review\n",
        "df['text_split'] = df['Review'].apply(lambda x: split_text(x))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ppKgyiaMabPV"
      },
      "outputs": [],
      "source": [
        "import google.generativeai as genai\n",
        "from chromadb import Documents, EmbeddingFunction, Embeddings\n",
        "import os\n",
        "import chromadb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "42lF80NEScb2"
      },
      "outputs": [],
      "source": [
        "class GeminiEmbeddingFunction(EmbeddingFunction):\n",
        "    \"\"\"\n",
        "    Custom embedding function using the Gemini AI API for document retrieval.\n",
        "\n",
        "    This class extends the EmbeddingFunction class and implements the __call__ method\n",
        "    to generate embeddings for a given set of documents using the Gemini AI API.\n",
        "\n",
        "    Parameters:\n",
        "    - input (Documents): A collection of documents to be embedded.\n",
        "\n",
        "    Returns:\n",
        "    - Embeddings: Embeddings generated for the input documents.\n",
        "\n",
        "    Raises:\n",
        "    - ValueError: If the Gemini API Key is not provided as an environment variable (GEMINI_API_KEY).\n",
        "\n",
        "    Example:\n",
        "    >>> gemini_embedding_function = GeminiEmbeddingFunction()\n",
        "    >>> input_documents = Documents([\"Document 1\", \"Document 2\", \"Document 3\"])\n",
        "    >>> embeddings_result = gemini_embedding_function(input_documents)\n",
        "    >>> print(embeddings_result)\n",
        "    Embeddings for the input documents generated by the Gemini AI API.\n",
        "    \"\"\"\n",
        "    def __call__(self, input: Documents) -> Embeddings:\n",
        "        gemini_api_key = os.getenv(\"GEMINI_API_KEY\")\n",
        "        if not gemini_api_key:\n",
        "            raise ValueError(\"Gemini API Key not provided. Please provide GEMINI_API_KEY as an environment variable\")\n",
        "        genai.configure(api_key=gemini_api_key)\n",
        "        model = \"models/embedding-001\"\n",
        "        title = \"Custom query\"\n",
        "        return genai.embed_content(model=model,\n",
        "                                   content=input,\n",
        "                                   task_type=\"retrieval_document\",\n",
        "                                   title=title)[\"embedding\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PAPEcmDibrFE"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import chromadb\n",
        "\n",
        "def create_chroma_db(df, path, name):\n",
        "    \"\"\"\n",
        "    Creates a Chroma database using the provided DataFrame, path, and collection name.\n",
        "\n",
        "    Parameters:\n",
        "    - df (DataFrame): DataFrame with a column named 'text_split' where each row contains a list of non-empty substrings.\n",
        "    - path (str): The path where the Chroma database will be stored.\n",
        "    - name (str): The name of the collection within the Chroma database.\n",
        "\n",
        "    Returns:\n",
        "    - Tuple[chromadb.Collection, str]: A tuple containing the created Chroma Collection and its name.\n",
        "    \"\"\"\n",
        "    documents = df['text_split'].tolist()\n",
        "    chroma_client = chromadb.PersistentClient(path=path)\n",
        "    db = chroma_client.create_collection(name=name, embedding_function=GeminiEmbeddingFunction())\n",
        "\n",
        "    for i, d in enumerate(documents):\n",
        "        db.add(documents=d, ids=str(i))\n",
        "\n",
        "    return db, name\n",
        "\n",
        "\n",
        "# Specify the path and name for the Chroma database\n",
        "chroma_path = '/content/target_dataset'\n",
        "chroma_name = 'reviews_collections'\n",
        "\n",
        "# Create the Chroma database\n",
        "db, collection_name = create_chroma_db(df, path=chroma_path, name=chroma_name)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZJh9y5866-Df"
      },
      "outputs": [],
      "source": [
        "def load_chroma_collection(path, name):\n",
        "    \"\"\"\n",
        "    Loads an existing Chroma collection from the specified path with the given name.\n",
        "\n",
        "    Parameters:\n",
        "    - path (str): The path where the Chroma database is stored.\n",
        "    - name (str): The name of the collection within the Chroma database.\n",
        "\n",
        "    Returns:\n",
        "    - chromadb.Collection: The loaded Chroma Collection.\n",
        "    \"\"\"\n",
        "    chroma_client = chromadb.PersistentClient(path=path)\n",
        "    db = chroma_client.get_collection(name=name, embedding_function=GeminiEmbeddingFunction())\n",
        "\n",
        "    return db\n",
        "\n",
        "db=load_chroma_collection(path='/content/target_dataset', name=\"reviews_collections\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TovcGXnEs1wa"
      },
      "outputs": [],
      "source": [
        "def get_relevant_passage(query, db, n_results):\n",
        "  passage = db.query(query_texts=[query], n_results=n_results)['documents'][0]\n",
        "  return passage\n",
        "\n",
        "#Example usage\n",
        "relevant_text = get_relevant_passage(query=\"Sanctions on Russia\",db=db,n_results=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Seril8uQuZ1h"
      },
      "outputs": [],
      "source": [
        "def make_rag_prompt(query, relevant_passage):\n",
        "  escaped = relevant_passage.replace(\"'\", \"\").replace('\"', \"\").replace(\"\\n\", \" \")\n",
        "  #user can change the prompt according to the need\n",
        "  prompt = (\"\"\"Fill the [MASK] with diverse words related to doctors and hospitals, which makes the review semantically and contextually correct according to an doctor review. The review must contain words so that it seems like a proper review given to a doctor or hospital by its patient.\n",
        "  QUESTION: '{query}'\n",
        "  PASSAGE: '{relevant_passage}'\n",
        "\n",
        "  ANSWER:\n",
        "  \"\"\").format(query=query, relevant_passage=escaped)\n",
        "\n",
        "  return prompt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZHCQXw0bsgIo"
      },
      "outputs": [],
      "source": [
        "import google.generativeai as genai\n",
        "def generate_answer_api(prompt):\n",
        "    gemini_api_key = os.getenv(\"GEMINI_API_KEY\")\n",
        "    if not gemini_api_key:\n",
        "        raise ValueError(\"Gemini API Key not provided. Please provide GEMINI_API_KEY as an environment variable\")\n",
        "    genai.configure(api_key=gemini_api_key)\n",
        "    model = genai.GenerativeModel('gemini-pro')\n",
        "    answer = model.generate_content(prompt)\n",
        "    return answer.text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mcqE2IgqsmxU"
      },
      "outputs": [],
      "source": [
        "def generate_answer(db,query):\n",
        "    #retrieve top 3 relevant text chunks\n",
        "    relevant_text = get_relevant_passage(query,db,n_results=3)\n",
        "    prompt = make_rag_prompt(query,\n",
        "                             relevant_passage=\"\".join(relevant_text)) # joining the relevant chunks to create a single passage\n",
        "    answer = generate_answer_api(prompt)\n",
        "\n",
        "    return answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Q0pmifqubYH"
      },
      "outputs": [],
      "source": [
        "db=load_chroma_collection(path='/content/target_dataset', #replace with path of your persistent directory\n",
        "                          name=\"reviews_collections\") #replace with the collection name\n",
        "\n",
        "answer = generate_answer(db,\"i love the [MASK] of [MASK]\")\n",
        "print(answer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lyEQCJmv-qh"
      },
      "source": [
        "Uploading folder to Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gzeyYQb2ukkK"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import shutil\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oa-f_vWewGpl"
      },
      "outputs": [],
      "source": [
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Path to the folder you want to upload\n",
        "folder_path = '/content/target_dataset'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HGuQ9L2mwBXH"
      },
      "outputs": [],
      "source": [
        "# Zip the folder\n",
        "shutil.make_archive('/content/target_dataset', 'zip', folder_path)\n",
        "\n",
        "# Destination path in Google Drive\n",
        "destination_path = '/content/drive/My Drive/'\n",
        "\n",
        "# Move the zipped folder to Google Drive\n",
        "shutil.move('/content/target_dataset.zip', destination_path)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}